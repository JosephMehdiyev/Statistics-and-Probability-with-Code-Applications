\chapter{Hypothesis Testing and p-value}
\section{Null and Alternate Hypothesis}
The hypothesis testing is very similar to the scientific method.
Scientists across the different fields use scientific method for their academical purposes.  The observe, formulate a theory, experiment and test the theory. There is a similar method called \textbf{hypothesis testing} for statistical inference. First, we will introduce some notations and definitions,
\begin{definition}
    \textbf{Null Hypothesis}, denoted by $H_0$, is the hypothesis to be tested.\newline
    \textbf{Alternate Hypothesis}, denoted by $H_1$, is the hypothesis contradictory to the null hypothesis. We usually try to support, since this way we could use \textit{proof by contradiction}. \
    If our evidence (data) favors the  alternative hypothesis, we reject the null hypothesis. Formally, we wish to test,
    \[H_0  : \theta  \in \Theta_0 \qquad or \qquad H_1 : \theta \in \Theta_1 \]
    Where $\Theta_0$ and $\Theta_1$ are disjoint sets of parameter space $\Theta$.
\end{definition}
\begin{example}
    Let $X_1,...,X_n \sim N(\mu, \sigma^2)$  with known variance $\sigma^2$ and uknown mean $\mu$. We wish to test the hypothesis,
    \[ H_0: \mu = \mu_0 \qquad or \qquad H_1: \mu  \neq \mu_0 \]
\end{example}
In order to test the hypothesis, it is logical to calculate $\overline{X}$ and compare it with $\mu_0$. It is reasonable to reject $H_0$ if $\overline{X}$ is far away than $\mu_0$. But how much far away exaclty? \newline
\textbf{Rejection or Critical Region} is a set denoted by $R$ to describe ``how far away'' the result can be. If the result is in the set $R$, we reject the hypothesis.
\begin{definition}
    The \textbf{Critical Region} is defined as,
    \[ R = \biggl \{ x : T(x) > c \biggr \} \]
    Here, $c$ is called \textbf{critical value}, and $T$ is a \textbf{test statistic} to help testing our hypothesis.
    The main question in hypothesis testing is find appropriate $T$ and $c$. 
\end{definition}
In above example, $\overline{X}$ is our $T$. We will learn about finding $c$ now.
\newline

A hypothesis in the form of $\theta = \theta_0$ is called \textbf{simple} i.e $\theta$ has only one value, while in the form of $\theta > \theta_0$ or $\theta < \theta_0$ is called \textbf{composite} i.e $\theta$ has multiple values

There are $4$ different possibilities we can conclude from our test. See the table for the brief introduction.\newline
If $H_0$ is true, and we reject it, we call this error \textbf{type I error}. Similarly, if $H_1$ is true and we keep the $H_0$, (or reject $H_1$) we call this error \textbf{type II error}. Summarize this in table,
\begin{center}
\begin{tabular}{|c|c|p{4.1cm}|}
    \hline
     & Retain Null & Reject Null \\
    \hline
    $H_0$ \text{true} & ($1 - \alpha$) & type I error ($\alpha$) signifigance level of the test\\
    \hline
    $H_1$  \text{true} & type II error ($\beta$) &  power of the test ($1 - \beta$)\\
    \hline
\end{tabular}
\end{center}
\begin{definition}
    The $\textbf{power function}$ of a test with critical region $R$ is a function defined as,
    \[ \beta (\theta) = P_{\theta}( X \in R)\]
    that is, $\beta(\theta)$ represents the  probability of rejecting $H_0$ if $\theta \in \Theta_0 \cup \Theta_1$ i.e $H_0$ or $H_1$ true. It is very general\\
    The \textbf{size} of the test is defined by,
    \[ \alpha = \sup_{\theta \in \Theta_{0}} \beta(\theta) \]
    that is, for $\theta$ that $H_0$ is true, $\alpha$ is the worst case scenario probability, representing \textbf{type I error}. We also call this probability \textbf{signifigance level} of the test.\\
\end{definition}

\section{References}
\begin{enumerate}
    \item \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_test#Definition_of_terms}
    \item \url{https://stats.stackexchange.com/questions/183800/how-to-understand-the-size-of-hypothesis-tests?rq=1}
\end{enumerate}
