\chapter{Hypothesis Testing and p-value}
\section{Null and Alternate Hypothesis}
The hypothesis testing is very similar to the scientific method.
Scientists across the different fields use scientific method for their academical purposes.  The observe, formulate a theory, experiment and test the theory. There is a similar method called \textbf{hypothesis testing} for statistical inference. First, we will introduce some notations and definitions,
\begin{definition}
    \textbf{Null Hypothesis}, denoted by $H_0$, is the hypothesis to be tested.\newline
    \textbf{Alternate Hypothesis}, denoted by $H_1$, is the hypothesis contradictory to the null hypothesis. We usually try to support, since this way we could use \textit{proof by contradiction}. \
    If our evidence (data) favors the  alternative hypothesis, we reject the null hypothesis. Formally, we wish to test,
    \[H_0  : \theta  \in \Theta_0 \qquad or \qquad H_1 : \theta \in \Theta_1 \]
    Where $\Theta_0$ and $\Theta_1$ are disjoint sets of parameter space $\Theta$.
\end{definition}
\begin{example}
    Let $X_1,...,X_n \sim N(\mu, \sigma^2)$  with known variance $\sigma^2$ and uknown mean $\mu$. We wish to test the hypothesis,
    \[ H_0: \mu = \mu_0 \qquad or \qquad H_1: \mu  \neq \mu_0 \]
\end{example}
In order to test the hypothesis, it is logical to calculate $\overline{X}$ and compare it with $\mu_0$. It is reasonable to reject $H_0$ if $\overline{X}$ is far away than $\mu_0$. But how much far away exaclty? \newline
\textbf{Rejection or Critical Region} is a set denoted by $R$ to describe ``how far away'' the result can be. If the result is in the set $R$, we reject the hypothesis.
\begin{definition}
    The \textbf{Critical Region} is defined as,
    \[ R = \biggl \{ x : T(x) > c \biggr \} \]
    Here, $c$ is called \textbf{critical value}, and $T$ is a \textbf{test statistic} to help testing our hypothesis.
    The main question in hypothesis testing is find appropriate $T$ and $c$. 
\end{definition}
In above example, $\overline{X}$ is our $T$. We will learn about finding $c$ now.
\newline

There are $4$ different possibilities we can conclude from our test. See the table for the brief introduction.\newline
If $H_0$ is true, and we reject it, we call this error \textbf{type I error}. The probability of type I error is denoted as $\alpha$. $\alpha$ is also called \textbf{size/level of the test}. Similarly, if $H_1$ is true and we keep the $H_0$, (or reject $H_1$) we call this error \textbf{type II error}. The probability of type II error is denoted as $\beta$. Summarize this in table,
\begin{center}
\begin{tabular}{|c|c|p{3.8cm}|}
    \hline
     & Retain Null & Reject Null \\
    \hline
    $H_0$ \text{true} & ($1 - \alpha$) & type I error $(\alpha)$\\
    \hline
    $H_1$  \text{true} & type II error $(\beta)$ &  power of the test ($1 - \beta$)\\
    \hline
\end{tabular}
\end{center}
\begin{definition}
    The $\textbf{power function}$ of a test with critical region $R$ is a function that gives the \textbf{power of the hypothesis test}, that is $(1- \beta)$, defined as,
    \[ \pi (\theta) = P( X \in R)\]
    Some of the  books notate this function as $B(\theta)$, $\op{power(\theta)}$ and even $\beta(\theta)$. \
    \textbf{The power of the hypothesis test}, in literal sense, measures how powerful our hypothesis test is i.e the probability of rejecting $H_0$ while $H_1$ is true. It is commonly denoted as $1- \beta$. See the table for more clarity.
\end{definition}

